---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: home
---

![Strikingly visible Purkinje neurons from the cerebellum of a dog](https://raw.githubusercontent.com/mdabagia/nemo/master/docs/assets/images/Neurons_(Purkinje_cells).jpg)



NEMO is a mathematical and computational model of the brain, meant to provide a concrete hypothesis as to how complex cognition can arise from the activity of neurons. Its exploration and development is an ongoing project, initiated by [Christos Papadimitriou](https://www.engineering.columbia.edu/faculty-staff/directory/christos-papadimitriou), [Santosh Vempala](https://faculty.cc.gatech.edu/~vempala/), [Max Dabagia](https://mdabagia.github.io/), and [Dan Mitropolsky](https://dmitropolsky.github.io/). 

This website outlines the NEMO model and collects the main results related to it. NEMO is far from a complete explanation about how intelligence arises from the brain, and is best considered a set of core assumptions that will likely be expanded in the future to yield a model that could genuinely explain cognition.

The content of this site draws from several papers (in chronological order):

* [Christos Papadimitriou & Santosh Vempala: "Random Projection in the Brain and Computation with Assemblies of Neurons." 10th Innovations in Theoretical Computer Science (2019).](https://par.nsf.gov/servlets/purl/10094284)
* [Christos Papadimitriou, Santosh Vempala, Daniel Mitropolsky, Michael Collins, & Wolfgang Maass: "Brain computation by assemblies of neurons." *Proceedings of the National Academy of Sciences* (2020).](https://www.pnas.org/doi/full/10.1073/pnas.2001893117)
* [Max Dabagia, Christos Papadimitriou, & Santosh Vempala: "Assemblies of neurons learn to classify well-separated distributions." Conference on Learning Theory, PMLR (2022).](https://proceedings.mlr.press/v178/dabagia22a.html)
* [Daniel Mitropolsky, Michael Collins, & Christos H. Papadimitriou: "A biologically plausible parser." *Transactions of the Association for Computational Linguistics* (2021).](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00432/108608/A-Biologically-Plausible-Parser)
* [Daniel Mitropolsky, Adiba Ejaz, Mirah Shi, Mihalis Yannakakis, & Christos Papadimitriou: "Center-embedding and constituency in the brain and a new characterization of context-free languages." arXiv (2022).](https://arxiv.org/abs/2206.13217)
* [Francesco d'Amore, Daniel Mitropolsky, Pierluigi Crescenzi, Emanuele Natale, & Christos Papadimitriou: "Planning with biological neurons and synapses." AAAI (2022).](https://aaai.org/papers/00021-planning-with-biological-neurons-and-synapses/)
* [Daniel Mitropolsky & Christos Papadimitriou: "The Architecture of a Biologically Plausible Language Organ." arXiv (2023).](https://arxiv.org/abs/2306.15364)
* [Max Dabagia, Christos Papadimitriou, Santosh Vempala: "Computation with Sequences of Assemblies in a Model of the Brain." International Conference on Algorithmic Learning (2024); *Neural Computation* (2025).](https://direct.mit.edu/neco/article-abstract/37/1/193/124822/Computation-With-Sequences-of-Assemblies-in-a)
* [Max Dabagia, Daniel Mitropolsky, Christos Papadimitriou, & Santosh Vempala: "Coin-Flipping In The Brain: Statistical Learning with Neuronal Assemblies." arXiv (2024).](https://arxiv.org/abs/2406.07715)




